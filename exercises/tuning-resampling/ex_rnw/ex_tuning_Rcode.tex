We want to predict the median value of owner-occupied homes
(variable \textit{medv}) in the area of Boston. Therefore
we want to use a K-nearest neighbors algorithm. We have already loaded the
corresponding task:

\begin{Schunk}
\begin{Sinput}
> library(mlr3)
> library(mlr3learners)
> task = tsk("boston_housing")
> nrow_task <- (task$backend$nrow)
> lrn_knn = lrn("regr.kknn")
\end{Sinput}
\end{Schunk}

However, we are not sure what number of neighbors (k) yields the best result.
This is why we want to use tuning to determine the best value for k.
We assume that it might be somewhere in the range from 1 to 100.

\begin{enumerate}\bfseries
  \item[1)] Define a meaningful search space for the hyperparameter k.
\end{enumerate}

Furthermore, we want to use random search to search our defined search space.
In addition, we only want to carry out the tuning a maximum of 80 times.

\begin{enumerate}\bfseries
  \item[2)] Think about what random search actually means with regard to the
  search space and implement it! Furthermore, add suitable stopping criterion.
\end{enumerate}

With the help of these building blocks (search space, optimization algorithm
(random search) and stopping criterion), we can define the basic
framework of the tuning procedure.

\begin{enumerate}\bfseries
  \item[4)] Put these building blocks together so that they form the basic
  structure of a tuning procedure. Think about what tuning actually means (Keyword: iterative) and how
  to translate this into code!
\end{enumerate}

However, we still need to define which resampling method is supposed to be used
during tuning. We want to use a 5-fold CV and use the MSE in each iteration to
calculate the estimated performance of the respective split.

\begin{enumerate}\bfseries
  \item[5)] Implement the 5-fold CV in the context of the tuning procedure
  specified above. You can use and modify the learner specified in the code
  block above. Keep in mind, that:
  \begin{itemize}
  \item The result of one CV is the average of the estimated performances
  per split.
  \item The number of k of the learner needs to vary depending on the tuning
  step we are in.
  \item Take a look at the code fragment below to get some inspiration.
  \end{itemize}
\end{enumerate}

\begin{Schunk}
\begin{Sinput}
> do_CV <- function(folds, k){
+   ....
+   # CV iterations
+   for (i in seq(folds)) {
+     ...
+   }
+   return(...)
+ }
\end{Sinput}
\end{Schunk}

Now, the last step we have to do is to plug our resampling strategy for tuning
into the tuning framework from 5)!
