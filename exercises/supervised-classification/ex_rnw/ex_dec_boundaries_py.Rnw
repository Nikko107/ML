We will now visualize how well different learners classify the three-class 
\texttt{cassini} data set.
Import \texttt{cassini\_data.csv}, perturb the \texttt{x.2} dimension 
with Gaussian noise (mean 0, standard deviation 0.5), 
and consider the classifiers already introduced in the lecture: 

\begin{itemize}
  \item LDA,
  \item QDA, and
  \item Naive Bayes.
\end{itemize}

Plot the learners' decision boundaries.
Can you spot differences in separation ability?

(Note that logistic regression cannot handle more than two classes and is 
therefore not listed here.)