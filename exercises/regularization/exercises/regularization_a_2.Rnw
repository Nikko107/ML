Suppose we observe 6 data pairs and want to describe the underlying relationship between target $y$ and feature $\xv$.

\begin{center}
  \begin{tabular}{ | c | c | c | c | c | c | c | }
    \hline
$\xv$ & 0.56 & 0.22 & 1.7 & 0.63 & 0.36 & 1.2 \\ \hline
y & 160 & 150 & 175 & 185 & 165 & 170 \\
    \hline
  \end{tabular}
\end{center}

We want wo train a linear model $\fxi = \theta_0 + \theta_1 \xi$ with L2 loss and ridge regularization.

\begin{itemize}
    \item[a)] Derive the gradient descent update rule for a linear model with L2 and ridge regularization.
    \item[b)] Compute one gradient descent update step from $\thetab^{[0]} = (0,0)$ with a stepsize of $\alpha = 0.1$ and penatly $\lambda = 0.1$.
\end{itemize}
