\begin{enumerate}
\item[1)] The generalization error is the expected (future) performance of a learner $\inducer$ trained on $\ntrain$ observations, and evaluated on $\Dtest$ with performance measure $\rho$. As any such performance estimate depends on the concrete sampling of $\Dtest$ from $\Pxy$, we are interested of the limit of this expectation value, as $\ntest\rightarrow\infty$.
\item[2)] One samples $\Dtrain$ of size $\ntrain = 100$ and $\Dtest$ of size $\ntest$ $k$ times from $\Pxy$ (independently). Each time, the learner $\inducer$ is trained on $\Dtraini[i]$, and the respective performance $\rho$ is evaluated on $\Dtesti[i]$. For $k,\ntest\rightarrow\infty$, the average performance $\frac{1}{k}\sumik \rho \left(\yv_{\Jtesti[i]}, {\F_{\Jtesti[i],\inducer(\Dtraini[i])}}\right)$ converges to $\GE(\inducer, \ntrain = 100, \rho)$.
\item[3)] As $\ntrain$ must be smaller than $n$, the estimator is a pessimistically biased estimator of $\GE(\inducer, \ntrain, \rho)$, as we are not using all available data for training. In the context of regression tasks and performance measures MSE or MAE, pessimistic bias means:
\begin{align}
\E\left[{\GEh_{\Jtrain, \Jtest}(\inducer, |\Jtrain|, \rho)}\right] > \GE(\inducer, \ntrain, \rho)
\end{align}
\item[4)] If one chooses a large $\ntrain$, $\ntest$ is small, and the estimator has a large variance. 
\end{enumerate}