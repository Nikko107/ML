\begin{enumerate}[a)]

  \item Since the polynomial learner clearly achieves a better fit for the 
  training data and some observations lie rather far from the regression line, 
  which is strongly penalized by $L2$ loss, it will have lower empirical risk 
  than the linear learner.
  
  \item First and foremost, evaluation on the training data is almost never a 
  good idea.
  Under certain conditions the training error does tell us something about 
  generalization ability, but for flexible learners and/or small training data 
  it is deceptive due to optimistic bias.
  In this particular situation, we have few training observations and quite 
  some points that look a little extreme.
  A low training error might be achieved by a learner that fits every 
  quirk in the training data but generalizes poorly to unseen points with only 
  slightly different distribution.
  Evaluation on separate test data is therefore non-negotiable.
  
  \item We fit the polynomial and linear learner and then compute the squared 
  and absolute differences between their respective predictions and the 
  true target values:
  
      <<echo=TRUE, message=FALSE>>=

# define train data including outlier
set.seed(123)
x_train <- seq(10, 15, length.out = 50)
y_train <- 10 + 3 * sin(0.15 * pi * x_train) + rnorm(length(x_train), sd = 0.5)
data_train <- data.frame(x = x_train, y = y_train)

# define test data, which contains one rather extreme point
set.seed(321)
x_test <- seq(10, 15, length.out = 19)
y_test <- 10 + 3 * sin(0.15 * pi * x_test) + rnorm(length(x_test), sd = 0.5)
data_test <- data.frame(x = c(x_test, 15), y = c(y_test, 10))

# train learners
polynomial_learner <- lm(y ~ poly(x, 21), data_train)
linear_learner <- lm(y ~ x, data_train)

# predict with both learners
y_polynomial <- predict(polynomial_learner, data_test)
y_lm <- predict(linear_learner, data_test)

# compute errors
abs_differences <- lapply(
  list(y_polynomial, y_lm), 
  function(i) abs(data_test$y - i))
errors_mse <- sapply(abs_differences, function(i) mean(i^2))
errors_mae <- sapply(abs_differences, mean)

print(c(errors_mse, errors_mae))
  The picture is inconclusive: based on MSE, we should prefer the complex 
  polynomial model, while MAE tells us to pick the linear one.
  It is important to understand that the choices of inner and outer loss 
  functions encode our requirements and may have substantial impact on the 
  result.
  Here, following the MAE assessment would signify preference for a 
  robust model.
\end{enumerate}
