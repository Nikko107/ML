{
  "hash": "455d0600fc1474c9f6e9d83694826c1f",
  "result": {
    "markdown": "---\ntitle: \"Exercise 1 -- ML Basics\"\nsubtitle: \"[Introduction to Machine Learning](https://slds-lmu.github.io/i2ml/)\"\nnotebook-view:\n  - notebook: _r.ipynb\n    title: \"Notebook for R\"\n  - notebook: _python.ipynb\n    title: \"Notebook for Python\"  \n---\n\n\n::: {.content-hidden when-format=\"pdf\"}\n::: {.hidden}\n$$\n\\renewcommand{\\bm}{\\boldsymbol}\n\\renewcommand{\\mathds}{\\mathbb}\n\n% math spaces\n\\ifdefined\\N\n\\renewcommand{\\N}{\\mathds{N}} % N, naturals\n\\else \\newcommand{\\N}{\\mathds{N}} \\fi \n\\newcommand{\\Z}{\\mathds{Z}} % Z, integers\n\\newcommand{\\Q}{\\mathds{Q}} % Q, rationals\n\\newcommand{\\R}{\\mathds{R}} % R, reals\n\\ifdefined\\C \n  \\renewcommand{\\C}{\\mathds{C}} % C, complex\n\\else \\newcommand{\\C}{\\mathds{C}} \\fi\n\\newcommand{\\continuous}{\\mathcal{C}} % C, space of continuous functions\n\\newcommand{\\M}{\\mathcal{M}} % machine numbers\n\\newcommand{\\epsm}{\\epsilon_m} % maximum error\n% counting / finite sets\n\\newcommand{\\setzo}{\\{0, 1\\}} % set 0, 1\n\\newcommand{\\setmp}{\\{-1, +1\\}} % set -1, 1\n\\newcommand{\\unitint}{[0, 1]} % unit interval\n% basic math stuff\n\\newcommand{\\xt}{\\tilde x} % x tilde\n\\newcommand{\\argmax}{\\operatorname{arg\\,max}} % argmax\n\\newcommand{\\argmin}{\\operatorname{arg\\,min}} % argmin\n\\newcommand{\\argminlim}{\\mathop{\\mathrm{arg\\,min}}\\limits} % argmax with limits\n\\newcommand{\\argmaxlim}{\\mathop{\\mathrm{arg\\,max}}\\limits} % argmin with limits  \n\\newcommand{\\sign}{\\operatorname{sign}} % sign, signum\n\\newcommand{\\I}{\\mathbb{I}} % I, indicator\n\\newcommand{\\order}{\\mathcal{O}} % O, order\n\\newcommand{\\pd}[2]{\\frac{\\partial{#1}}{\\partial #2}} % partial derivative\n\\newcommand{\\floorlr}[1]{\\left\\lfloor #1 \\right\\rfloor} % floor\n\\newcommand{\\ceillr}[1]{\\left\\lceil #1 \\right\\rceil} % ceiling\n% sums and products\n\\newcommand{\\sumin}{\\sum\\limits_{i=1}^n} % summation from i=1 to n\n\\newcommand{\\sumim}{\\sum\\limits_{i=1}^m} % summation from i=1 to m\n\\newcommand{\\sumjn}{\\sum\\limits_{j=1}^n} % summation from j=1 to p\n\\newcommand{\\sumjp}{\\sum\\limits_{j=1}^p} % summation from j=1 to p\n\\newcommand{\\sumik}{\\sum\\limits_{i=1}^k} % summation from i=1 to k\n\\newcommand{\\sumkg}{\\sum\\limits_{k=1}^g} % summation from k=1 to g\n\\newcommand{\\sumjg}{\\sum\\limits_{j=1}^g} % summation from j=1 to g\n\\newcommand{\\meanin}{\\frac{1}{n} \\sum\\limits_{i=1}^n} % mean from i=1 to n\n\\newcommand{\\meanim}{\\frac{1}{m} \\sum\\limits_{i=1}^m} % mean from i=1 to n\n\\newcommand{\\meankg}{\\frac{1}{g} \\sum\\limits_{k=1}^g} % mean from k=1 to g\n\\newcommand{\\prodin}{\\prod\\limits_{i=1}^n} % product from i=1 to n\n\\newcommand{\\prodkg}{\\prod\\limits_{k=1}^g} % product from k=1 to g\n\\newcommand{\\prodjp}{\\prod\\limits_{j=1}^p} % product from j=1 to p\n% linear algebra\n\\newcommand{\\one}{\\boldsymbol{1}} % 1, unitvector\n\\newcommand{\\zero}{\\mathbf{0}} % 0-vector\n\\newcommand{\\id}{\\boldsymbol{I}} % I, identity\n\\newcommand{\\diag}{\\operatorname{diag}} % diag, diagonal\n\\newcommand{\\trace}{\\operatorname{tr}} % tr, trace\n\\newcommand{\\spn}{\\operatorname{span}} % span\n\\newcommand{\\scp}[2]{\\left\\langle #1, #2 \\right\\rangle} % <.,.>, scalarproduct\n\\newcommand{\\mat}[1]{\\begin{pmatrix} #1 \\end{pmatrix}} % short pmatrix command\n\\newcommand{\\Amat}{\\mathbf{A}} % matrix A\n\\newcommand{\\Deltab}{\\mathbf{\\Delta}} % error term for vectors\n% basic probability + stats\n\\renewcommand{\\P}{\\mathds{P}} % P, probability\n\\newcommand{\\E}{\\mathds{E}} % E, expectation\n\\newcommand{\\var}{\\mathsf{Var}} % Var, variance\n\\newcommand{\\cov}{\\mathsf{Cov}} % Cov, covariance\n\\newcommand{\\corr}{\\mathsf{Corr}} % Corr, correlation\n\\newcommand{\\normal}{\\mathcal{N}} % N of the normal distribution\n\\newcommand{\\iid}{\\overset{i.i.d}{\\sim}} % dist with i.i.d superscript\n\\newcommand{\\distas}[1]{\\overset{#1}{\\sim}} % ... is distributed as ...\n\n\\newcommand{\\Xspace}{\\mathcal{X}} % X, input space\n\\newcommand{\\Yspace}{\\mathcal{Y}} % Y, output space\n\\newcommand{\\nset}{\\{1, \\ldots, n\\}} % set from 1 to n\n\\newcommand{\\pset}{\\{1, \\ldots, p\\}} % set from 1 to p\n\\newcommand{\\gset}{\\{1, \\ldots, g\\}} % set from 1 to g\n\\newcommand{\\Pxy}{\\mathbb{P}_{xy}} % P_xy\n\\newcommand{\\Exy}{\\mathbb{E}_{xy}} % E_xy: Expectation over random variables xy\n\\newcommand{\\xv}{\\mathbf{x}} % vector x (bold)\n\\newcommand{\\xtil}{\\tilde{\\mathbf{x}}} % vector x-tilde (bold)\n\\newcommand{\\yv}{\\mathbf{y}} % vector y (bold)\n\\newcommand{\\xy}{(\\xv, y)} % observation (x, y)\n\\newcommand{\\xvec}{\\left(x_1, \\ldots, x_p\\right)^\\top} % (x1, ..., xp) \n\\newcommand{\\Xmat}{\\mathbf{X}} % Design matrix\n\\newcommand{\\allDatasets}{\\mathds{D}} % The set of all datasets\n\\newcommand{\\allDatasetsn}{\\mathds{D}_n}  % The set of all datasets of size n \n\\newcommand{\\D}{\\mathcal{D}} % D, data\n\\newcommand{\\Dn}{\\D_n} % D_n, data of size n\n\\newcommand{\\Dtrain}{\\mathcal{D}_{\\text{train}}} % D_train, training set\n\\newcommand{\\Dtest}{\\mathcal{D}_{\\text{test}}} % D_test, test set\n\\newcommand{\\xyi}[1][i]{\\left(\\xv^{(#1)}, y^{(#1)}\\right)} % (x^i, y^i), i-th observation\n\\newcommand{\\Dset}{\\left( \\xyi[1], \\ldots, \\xyi[n]\\right)} % {(x1,y1)), ..., (xn,yn)}, data\n\\newcommand{\\defAllDatasetsn}{(\\Xspace \\times \\Yspace)^n} % Def. of the set of all datasets of size n \n\\newcommand{\\defAllDatasets}{\\bigcup_{n \\in \\N}(\\Xspace \\times \\Yspace)^n} % Def. of the set of all datasets \n\\newcommand{\\xdat}{\\left\\{ \\xv^{(1)}, \\ldots, \\xv^{(n)}\\right\\}} % {x1, ..., xn}, input data\n\\newcommand{\\ydat}{\\left\\{ \\yv^{(1)}, \\ldots, \\yv^{(n)}\\right\\}} % {y1, ..., yn}, input data\n\\newcommand{\\yvec}{\\left(y^{(1)}, \\hdots, y^{(n)}\\right)^\\top} % (y1, ..., yn), vector of outcomes\n\\renewcommand{\\xi}[1][i]{\\xv^{(#1)}} % x^i, i-th observed value of x\n\\newcommand{\\yi}[1][i]{y^{(#1)}} % y^i, i-th observed value of y \n\\newcommand{\\xivec}{\\left(x^{(i)}_1, \\ldots, x^{(i)}_p\\right)^\\top} % (x1^i, ..., xp^i), i-th observation vector\n\\newcommand{\\xj}{\\xv_j} % x_j, j-th feature\n\\newcommand{\\xjvec}{\\left(x^{(1)}_j, \\ldots, x^{(n)}_j\\right)^\\top} % (x^1_j, ..., x^n_j), j-th feature vector\n\\newcommand{\\phiv}{\\mathbf{\\phi}} % Basis transformation function phi\n\\newcommand{\\phixi}{\\mathbf{\\phi}^{(i)}} % Basis transformation of xi: phi^i := phi(xi)\n\n%%%%%% ml - models general\n\\newcommand{\\lamv}{\\bm{\\lambda}} % lambda vector, hyperconfiguration vector\n\\newcommand{\\Lam}{\\bm{\\Lambda}}\t % Lambda, space of all hpos\n% Inducer / Inducing algorithm\n\\newcommand{\\preimageInducer}{\\left(\\defAllDatasets\\right)\\times\\Lam} % Set of all datasets times the hyperparameter space\n\\newcommand{\\preimageInducerShort}{\\allDatasets\\times\\Lam} % Set of all datasets times the hyperparameter space\n% Inducer / Inducing algorithm\n\\newcommand{\\ind}{\\mathcal{I}} % Inducer, inducing algorithm, learning algorithm \n\n% continuous prediction function f\n\\newcommand{\\ftrue}{f_{\\text{true}}}  % True underlying function (if a statistical model is assumed)\n\\newcommand{\\ftruex}{\\ftrue(\\xv)} % True underlying function (if a statistical model is assumed)\n\\newcommand{\\fx}{f(\\xv)} % f(x), continuous prediction function\n\\newcommand{\\fdomains}{f: \\Xspace \\rightarrow \\R^g} % f with domain and co-domain\n\\newcommand{\\Hspace}{\\mathcal{H}} % hypothesis space where f is from\n\\newcommand{\\fbayes}{f^{\\ast}} % Bayes-optimal model\n\\newcommand{\\fxbayes}{f^{\\ast}(\\xv)} % Bayes-optimal model\n\\newcommand{\\fkx}[1][k]{f_{#1}(\\xv)} % f_j(x), discriminant component function\n\\newcommand{\\fh}{\\hat{f}} % f hat, estimated prediction function\n\\newcommand{\\fxh}{\\fh(\\xv)} % fhat(x)\n\\newcommand{\\fxt}{f(\\xv ~|~ \\thetab)} % f(x | theta)\n\\newcommand{\\fxi}{f\\left(\\xv^{(i)}\\right)} % f(x^(i))\n\\newcommand{\\fxih}{\\hat{f}\\left(\\xv^{(i)}\\right)} % f(x^(i))\n\\newcommand{\\fxit}{f\\left(\\xv^{(i)} ~|~ \\thetab\\right)} % f(x^(i) | theta)\n\\newcommand{\\fhD}{\\fh_{\\D}} % fhat_D, estimate of f based on D\n\\newcommand{\\fhDtrain}{\\fh_{\\Dtrain}} % fhat_Dtrain, estimate of f based on D\n\\newcommand{\\fhDnlam}{\\fh_{\\Dn, \\lamv}} %model learned on Dn with hp lambda\n\\newcommand{\\fhDlam}{\\fh_{\\D, \\lamv}} %model learned on D with hp lambda\n\\newcommand{\\fhDnlams}{\\fh_{\\Dn, \\lamv^\\ast}} %model learned on Dn with optimal hp lambda \n\\newcommand{\\fhDlams}{\\fh_{\\D, \\lamv^\\ast}} %model learned on D with optimal hp lambda \n\n% discrete prediction function h\n\\newcommand{\\hx}{h(\\xv)} % h(x), discrete prediction function\n\\newcommand{\\hh}{\\hat{h}} % h hat\n\\newcommand{\\hxh}{\\hat{h}(\\xv)} % hhat(x)\n\\newcommand{\\hxt}{h(\\xv | \\thetab)} % h(x | theta)\n\\newcommand{\\hxi}{h\\left(\\xi\\right)} % h(x^(i))\n\\newcommand{\\hxit}{h\\left(\\xi ~|~ \\thetab\\right)} % h(x^(i) | theta)\n\\newcommand{\\hbayes}{h^{\\ast}} % Bayes-optimal classification model\n\\newcommand{\\hxbayes}{h^{\\ast}(\\xv)} % Bayes-optimal classification model\n\n% yhat\n\\newcommand{\\yh}{\\hat{y}} % yhat for prediction of target\n\\newcommand{\\yih}{\\hat{y}^{(i)}} % yhat^(i) for prediction of ith targiet\n\\newcommand{\\resi}{\\yi- \\yih}\n\n% theta\n\\newcommand{\\thetah}{\\hat{\\theta}} % theta hat\n\\newcommand{\\thetab}{\\bm{\\theta}} % theta vector\n\\newcommand{\\thetabh}{\\bm{\\hat\\theta}} % theta vector hat\n\\newcommand{\\thetat}[1][t]{\\thetab^{[#1]}} % \n\\newcommand{\\thetatn}[1][t]{\\thetab^{[#1 +1]}} % \n\\newcommand{\\thetahDnlam}{\\thetabh_{\\Dn, \\lamv}} %theta learned on Dn with hp lambda\n\\newcommand{\\thetahDlam}{\\thetabh_{\\D, \\lamv}} %theta learned on D with hp lambda\n\\newcommand{\\mint}{\\min_{\\thetab \\in \\Theta}} % min problem theta\n\\newcommand{\\argmint}{\\argmin_{\\thetab \\in \\Theta}} % argmin theta\n\n% densities + probabilities\n% pdf of x \n\\newcommand{\\pdf}{p} % p\n\\newcommand{\\pdfx}{p(\\xv)} % p(x)\n\\newcommand{\\pixt}{\\pi(\\xv~|~ \\thetab)} % pi(x|theta), pdf of x given theta\n\\newcommand{\\pixit}{\\pi\\left(\\xi ~|~ \\thetab\\right)} % pi(x^i|theta), pdf of x given theta\n\\newcommand{\\pixii}{\\pi\\left(\\xi\\right)} % pi(x^i), pdf of i-th x \n\n% pdf of (x, y)\n\\newcommand{\\pdfxy}{p(\\xv,y)} % p(x, y)\n\\newcommand{\\pdfxyt}{p(\\xv, y ~|~ \\thetab)} % p(x, y | theta)\n\\newcommand{\\pdfxyit}{p\\left(\\xi, \\yi ~|~ \\thetab\\right)} % p(x^(i), y^(i) | theta)\n\n% pdf of x given y\n\\newcommand{\\pdfxyk}[1][k]{p(\\xv | y= #1)} % p(x | y = k)\n\\newcommand{\\lpdfxyk}[1][k]{\\log p(\\xv | y= #1)} % log p(x | y = k)\n\\newcommand{\\pdfxiyk}[1][k]{p\\left(\\xi | y= #1 \\right)} % p(x^i | y = k)\n\n% prior probabilities\n\\newcommand{\\pik}[1][k]{\\pi_{#1}} % pi_k, prior\n\\newcommand{\\lpik}[1][k]{\\log \\pi_{#1}} % log pi_k, log of the prior\n\\newcommand{\\pit}{\\pi(\\thetab)} % Prior probability of parameter theta\n\n% posterior probabilities\n\\newcommand{\\post}{\\P(y = 1 ~|~ \\xv)} % P(y = 1 | x), post. prob for y=1\n\\newcommand{\\postk}[1][k]{\\P(y = #1 ~|~ \\xv)} % P(y = k | y), post. prob for y=k\n\\newcommand{\\pidomains}{\\pi: \\Xspace \\rightarrow \\unitint} % pi with domain and co-domain\n\\newcommand{\\pibayes}{\\pi^{\\ast}} % Bayes-optimal classification model\n\\newcommand{\\pixbayes}{\\pi^{\\ast}(\\xv)} % Bayes-optimal classification model\n\\newcommand{\\pix}{\\pi(\\xv)} % pi(x), P(y = 1 | x)\n\\newcommand{\\piv}{\\bm{\\pi}} % pi, bold, as vector\n\\newcommand{\\pikx}[1][k]{\\pi_{#1}(\\xv)} % pi_k(x), P(y = k | x)\n\\newcommand{\\pikxt}[1][k]{\\pi_{#1}(\\xv ~|~ \\thetab)} % pi_k(x | theta), P(y = k | x, theta)\n\\newcommand{\\pixh}{\\hat \\pi(\\xv)} % pi(x) hat, P(y = 1 | x) hat\n\\newcommand{\\pikxh}[1][k]{\\hat \\pi_{#1}(\\xv)} % pi_k(x) hat, P(y = k | x) hat\n\\newcommand{\\pixih}{\\hat \\pi(\\xi)} % pi(x^(i)) with hat\n\\newcommand{\\pikxih}[1][k]{\\hat \\pi_{#1}(\\xi)} % pi_k(x^(i)) with hat\n\\newcommand{\\pdfygxt}{p(y ~|~\\xv, \\thetab)} % p(y | x, theta)\n\\newcommand{\\pdfyigxit}{p\\left(\\yi ~|~\\xi, \\thetab\\right)} % p(y^i |x^i, theta)\n\\newcommand{\\lpdfygxt}{\\log \\pdfygxt } % log p(y | x, theta)\n\\newcommand{\\lpdfyigxit}{\\log \\pdfyigxit} % log p(y^i |x^i, theta)\n\n% probababilistic\n\\newcommand{\\bayesrulek}[1][k]{\\frac{\\P(\\xv | y= #1) \\P(y= #1)}{\\P(\\xv)}} % Bayes rule\n\\newcommand{\\muk}{\\bm{\\mu_k}} % mean vector of class-k Gaussian (discr analysis) \n\n% residual and margin\n\\newcommand{\\eps}{\\epsilon} % residual, stochastic\n\\newcommand{\\epsi}{\\epsilon^{(i)}} % epsilon^i, residual, stochastic\n\\newcommand{\\epsh}{\\hat{\\epsilon}} % residual, estimated\n\\newcommand{\\yf}{y \\fx} % y f(x), margin\n\\newcommand{\\yfi}{\\yi \\fxi} % y^i f(x^i), margin\n\\newcommand{\\Sigmah}{\\hat \\Sigma} % estimated covariance matrix\n\\newcommand{\\Sigmahj}{\\hat \\Sigma_j} % estimated covariance matrix for the j-th class\n\n% ml - loss, risk, likelihood\n\\newcommand{\\Lyf}{L\\left(y, f\\right)} % L(y, f), loss function\n\\newcommand{\\Lypi}{L\\left(y, \\pi\\right)} % L(y, pi), loss function\n\\newcommand{\\Lxy}{L\\left(y, \\fx\\right)} % L(y, f(x)), loss function\n\\newcommand{\\Lxyi}{L\\left(\\yi, \\fxi\\right)} % loss of observation\n\\newcommand{\\Lxyt}{L\\left(y, \\fxt\\right)} % loss with f parameterized\n\\newcommand{\\Lxyit}{L\\left(\\yi, \\fxit\\right)} % loss of observation with f parameterized\n\\newcommand{\\Lxym}{L\\left(\\yi, f\\left(\\bm{\\tilde{x}}^{(i)} ~|~ \\thetab\\right)\\right)} % loss of observation with f parameterized\n\\newcommand{\\Lpixy}{L\\left(y, \\pix\\right)} % loss in classification\n\\newcommand{\\Lpiv}{L\\left(y, \\piv\\right)} % loss in classification\n\\newcommand{\\Lpixyi}{L\\left(\\yi, \\pixii\\right)} % loss of observation in classification\n\\newcommand{\\Lpixyt}{L\\left(y, \\pixt\\right)} % loss with pi parameterized\n\\newcommand{\\Lpixyit}{L\\left(\\yi, \\pixit\\right)} % loss of observation with pi parameterized\n\\newcommand{\\Lhxy}{L\\left(y, \\hx\\right)} % L(y, h(x)), loss function on discrete classes\n\\newcommand{\\Lr}{L\\left(r\\right)} % L(r), loss defined on residual (reg) / margin (classif)\n\\newcommand{\\lone}{|y - \\fx|} % L1 loss\n\\newcommand{\\ltwo}{\\left(y - \\fx\\right)^2} % L2 loss\n\\newcommand{\\lbernoullimp}{\\ln(1 + \\exp(-y \\cdot \\fx))} % Bernoulli loss for -1, +1 encoding\n\\newcommand{\\lbernoullizo}{- y \\cdot \\fx + \\log(1 + \\exp(\\fx))} % Bernoulli loss for 0, 1 encoding\n\\newcommand{\\lcrossent}{- y \\log \\left(\\pix\\right) - (1 - y) \\log \\left(1 - \\pix\\right)} % cross-entropy loss\n\\newcommand{\\lbrier}{\\left(\\pix - y \\right)^2} % Brier score\n\\newcommand{\\risk}{\\mathcal{R}} % R, risk\n\\newcommand{\\riskbayes}{\\mathcal{R}^\\ast}\n\\newcommand{\\riskf}{\\risk(f)} % R(f), risk\n\\newcommand{\\riskdef}{\\E_{y|\\xv}\\left(\\Lxy \\right)} % risk def (expected loss)\n\\newcommand{\\riskt}{\\mathcal{R}(\\thetab)} % R(theta), risk\n\\newcommand{\\riske}{\\mathcal{R}_{\\text{emp}}} % R_emp, empirical risk w/o factor 1 / n\n\\newcommand{\\riskeb}{\\bar{\\mathcal{R}}_{\\text{emp}}} % R_emp, empirical risk w/ factor 1 / n\n\\newcommand{\\riskef}{\\riske(f)} % R_emp(f)\n\\newcommand{\\risket}{\\mathcal{R}_{\\text{emp}}(\\thetab)} % R_emp(theta)\n\\newcommand{\\riskr}{\\mathcal{R}_{\\text{reg}}} % R_reg, regularized risk\n\\newcommand{\\riskrt}{\\mathcal{R}_{\\text{reg}}(\\thetab)} % R_reg(theta)\n\\newcommand{\\riskrf}{\\riskr(f)} % R_reg(f)\n\\newcommand{\\riskrth}{\\hat{\\mathcal{R}}_{\\text{reg}}(\\thetab)} % hat R_reg(theta)\n\\newcommand{\\risketh}{\\hat{\\mathcal{R}}_{\\text{emp}}(\\thetab)} % hat R_emp(theta)\n\\newcommand{\\LL}{\\mathcal{L}} % L, likelihood\n\\newcommand{\\LLt}{\\mathcal{L}(\\thetab)} % L(theta), likelihood\n\\newcommand{\\LLtx}{\\mathcal{L}(\\thetab | \\xv)} % L(theta|x), likelihood\n\\newcommand{\\logl}{\\ell} % l, log-likelihood\n\\newcommand{\\loglt}{\\logl(\\thetab)} % l(theta), log-likelihood\n\\newcommand{\\logltx}{\\logl(\\thetab | \\xv)} % l(theta|x), log-likelihood\n\\newcommand{\\errtrain}{\\text{err}_{\\text{train}}} % training error\n\\newcommand{\\errtest}{\\text{err}_{\\text{test}}} % test error\n\\newcommand{\\errexp}{\\overline{\\text{err}_{\\text{test}}}} % avg training error\n\n% lm\n\\newcommand{\\thx}{\\thetab^\\top \\xv} % linear model\n\\newcommand{\\olsest}{(\\Xmat^\\top \\Xmat)^{-1} \\Xmat^\\top \\yv} % OLS estimator in LM \n$$\n\n\n:::\n:::\n\n## Exercise 1: HRO in coding frameworks\n\n::: {.callout-note title=\"Learning goals\" icon=false}\nTBD\n:::\n\nThroughout the lecture, we will frequently use the `R` package \n`mlr3`, resp. the `Python` package \n`sklearn`, and its descendants, providing an integrated ecosystem for all \ncommon machine learning tasks.\nLet's recap the HRO principle and see how it is reflected in either `mlr3` or `sklearn`.\nAn overview of the most important objects and their usage, illustrated with \nnumerous examples, can be found at [the `mlr3` book](https://mlr3book.mlr-org.com/) and\n[the `scikit` documentation](https://scikit-learn.org/stable/index.html).\n\n***\nHow are the key concepts (i.e., hypothesis space, risk and optimization) \nyou learned about in the lecture videos implemented?\n  \n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#hro-objects |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_python.ipynb#hro-objects |  | echo:true,warning:false,asis:true,eval:false -->\n:::\n</details> \n:::\n\n***\nHave a look at`mlr3::tsk(\"iris\")` / `sklearn.datasets.load_iris`. What attributes does this object store?\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#hro-task |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_python.ipynb#hro-task |  | echo:true,warning:false,asis:true,eval:false -->\n:::\n</details> \n:::\n\n***\nInstantiate a regression tree learner. What are the different settings for this learner?\n\n<details> \n<summary>*Hint*</summary>\n::: {.panel-tabset}\n### R\nUse `lrn(\"regr.rpart\")` (`mlr3::mlr_learners$keys()` shows all available learners).\n\n### Python\nUse the `DecisionTreeRegressor` module and use `get_params()` to see all available settings.\n:::\n</details> \n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#hro-learner |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_python.ipynb#hro-learner |  | echo:true,warning:false,asis:true,eval:false -->\n:::\n</details> \n:::\n\n## Exercise 2: Loss functions for regression tasks\n\n::: {.callout-note title=\"Learning goals\" icon=false}\nTBD\n:::\n\nIn this exercise, we will examine loss functions for regression tasks \nsomewhat more in depth.\n\n::: {.cell}\n::: {.cell-output-display}\n![](regression_files/figure-pdf/unnamed-chunk-1-1.pdf)\n:::\n:::\n\nConsider the above linear regression task. How will the model \n  parameters be affected by adding the new outlier point (orange) if you use\n  $L1$ loss and $L2$ loss, respectively, \n  in the empirical risk? (You do not need to actually compute the \n  parameter values.)\n  \n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n$L2$ loss penalizes vertical distances to the regression line *quadratically*, while $L1$ only considers the *absolute*\ndistance. As the outlier point lies pretty far from the remaining training data, it will have a large loss with $L2$,\nand the regression line will pivot to the bottom right to minimize the resulting empirical risk. A model trained\nwith $L1$ loss is less susceptible to the outlier and will adjust only slightly to the new data.\n\n::: {.cell}\n::: {.cell-output-display}\n![](regression_files/figure-pdf/unnamed-chunk-2-1.pdf)\n:::\n:::\n\n</details> \n:::\n\n***\n\n::: {.cell}\n::: {.cell-output-display}\n![](regression_files/figure-pdf/unnamed-chunk-3-1.pdf)\n:::\n:::\n\nThe second plot visualizes another loss function popular in \n  regression tasks, the so-called *Huber loss* (depending on \n  $\\epsilon > 0$; here: $\\epsilon = 5$). \n  Describe how the Huber loss deals with residuals as compared to $L1$ and $L2$ \n  loss.\n  Can you guess its definition? \n  \n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nThe Huber loss combines the respective advantages of $L1$ and $L2$ loss: \n  it is smooth and (once) differentiable like $L2$ but does not punish larger \n  residuals as severely, leading to more robustness. \n  It is simply a (weighted) piecewise combination of both losses, \n  where $\\epsilon$ marks where $L2$ transits to $L1$ loss. The exact definition \n  is:\n    $$\n  \\Lxy = \\begin{cases}\n    \\frac{1}{2}(y - \\fx)^2  & \\text{ if } \\lone \\le \\epsilon \\\\\n    \\epsilon \\lone-\\frac{1}{2}\\epsilon^2 \\quad & \\text{ otherwise }\n    \\end{cases}, \\quad \\epsilon > 0\n  $$\n  In the plot we can see how the parabolic shape of the loss around 0 evolves \n  into an absolute-value function at $\\lone > \\epsilon = 5$.\n</details> \n:::\n\n\n\n## Exercise 3: Polynomial regression\n\n::: {.callout-note title=\"Learning goals\" icon=false}\nTBD\n:::\n\nAssume the following (noisy) data-generating process from which we have \nobserved 50 realizations: $$y = -3 + 5 \\cdot \n\\sin(0.4 \\pi x) + \\epsilon$$ with $\\epsilon \\, \\sim \\mathcal{N}(0, 1)$.\n\n***\nWe decide to model the data with a cubic polynomial (including intercept term). State the corresponding hypothesis space.\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nCubic means degree 3, so our hypothesis space will look as \nfollows:\n$$\\Hspace = \\{ \\fxt = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3 \n~|~ (\\theta_0, \\theta_1, \\theta_2, \\theta_3)^\\top \\in \\R^4 \\}$$\n</details>\n:::\n\n***  \nState the empirical risk w.r.t. $\\thetab$ for a member of the hypothesis space. Use $L2$ loss and be as explicit as possible.\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nThe empirical risk is:\n$$\\risket = \\sum_{i = 1}^{50} \\left(\\yi - \\left[ \\theta_0 + \\theta_1 x^{(i)} + \n\\theta_2 \\left( x^{(i)} \\right)^2 + \\theta_3 \\left( x^{(i)} \\right)^3 \\right] \n\\right)^2$$\n</details>\n:::\n\n::: {.content-hidden when-profile=\"b\"}\n***\n::: {.callout-tip icon=false title=\"Only for lecture group A\"}\n:::\nWe can minimize this risk using gradient descent. Derive the gradient of the empirical risk w.r.t $\\thetab$.\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nWe can \nfind the gradient just as we did for an intermediate result when we derived \nthe least-squares estimator:\n\n\\begin{align*}\n  \\nabla_{\\thetab} \\risket &=\n  \\pd{}{\\thetab} \\left \\| \\yv - \\Xmat \\thetab \\right \\|_2^2 \\\\\n  &= \\pd{}{\\thetab} \\left( \\left(\\yv - \\Xmat \\thetab\\right)^\\top \n  \\left(\\yv - \\Xmat \\thetab \\right) \\right) \\\\ \n  &= - 2 \\Xmat^\\top \\yv + 2 \\Xmat^\\top \\Xmat \\thetab\\\\\n  &= 2 \\cdot \\left( - \\Xmat^\\top \\yv + \\Xmat^\\top \n  \\Xmat \\thetab \\right)\n\\end{align*}\n</details>\n:::\n:::\n\n::: {.content-hidden when-profile=\"b\"}\n\n***\n::: {.callout-tip icon=false title=\"Only for lecture group A\"}\n::: \nUsing the result for the gradient, state the calculation to update the current \n  parameter $\\thetat$.\n  \n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nRecall that the idea of gradient descent (\\textit{descent}!) is to \n  traverse the risk surface in the direction of the \\textit{negative} gradient \n  as we are in search for the minimum.\n  Therefore, we will update our current parameter set $\\thetat$ with the \n  negative gradient of the current empirical risk w.r.t. $\\thetab$, scaled \n  by learning rate (or step size) $\\alpha$:\n  \n  $$\\thetatn = \\thetat - \\alpha \\cdot \\nabla_{\\thetab} \\riske(\\thetat).$$\n  \n  Note that the $L2$-induced multiplicative constant of 2 in the gradient \n  can simply be absorbed by $\\tilde \\alpha := \\tfrac{1}{2} \\alpha$:\n  \n  \\begin{align*}\n    \\underbrace{\\thetatn}_{p \\times 1} &= \\underbrace{\\thetat}_{p \\times 1} - \n    \\tilde \\alpha \\cdot \\left( - \\underbrace{\\Xmat^\\top \\phantom{y}}_{\n    p \\times n} \\underbrace{\\yv}_{n \\times 1} + \\underbrace{\n    \\Xmat^\\top \\Xmat \\phantom{y}}_{p \\times p} \n    \\underbrace{\\thetat \\phantom{y}}_{p \\times 1} \n    \\right) \\\\\n    \\mat{\\theta_1 \\\\ \\theta_2 \\\\ \\vdots \\\\ \\theta_p}^{[t + 1]} &= \n    \\mat{\\theta_1 \\\\ \\theta_2 \\\\ \\vdots \\\\ \\theta_p}^{[t]} - \\tilde \\alpha \n    \\cdot \\left( - \\Xmat^\\top \\yv + \\Xmat^\\top \\Xmat \n    \\mat{\\theta_1 \\\\ \\theta_2 \\\\ \\vdots \\\\ \\theta_p}^{[t]} \\right)\n  \\end{align*}\n  \n  What actually happens here: we update each component of our current \n  parameter vector $\\thetat$ in the \\textit{direction} of the negative \n  gradient, i.e., following the steepest downward slope, and also by an \n  \\textit{amount} that depends on the value of the gradient.\n  \n  In order to see what that means it is helpful to recall that the gradient \n  $\\nabla_{\\thetab} \\risket$ tells us about the effect (infinitesimally small) \n  changes in $\\thetab$ have on $\\risket$.\n  Therefore, gradient updates focus on  influential components, and we \n  proceed more quickly along the important dimensions.\n</details>\n:::  \n:::\n\n***\nYou will not be able to fit the data perfectly with a cubic polynomial.\n  Describe the advantages and disadvantages that a more \n  flexible model class would have. \n  Would you opt for a more flexible learner?\n  \n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\nWe see that, for example, the first model in exercise b) fits the data \nfairly well but not perfectly.\nChoosing a more flexible function (a polynomial of higher degree or a function \nfrom an entirely different, more complex, model class) might be advantageous:\n\n* We would be able to trace the observations more closely if our \nfunction were less smooth, and thus reduce empirical risk.\nOn the other hand, flexibility also has drawbacks:\n\n* Flexible model classes often have more parameters, making training \nharder.\n\n* We might run into a phenomenon called *overfitting*. \nRecall that our ultimate goal is to make predictions on *new* \nobservations. \nHowever, fitting every quirk of the training observations -- possibly caused \nby imprecise measurement or other factors of randomness/error -- will not \ngeneralize so well to new data.\n\nIn the end, we need to balance model fit and generalization. \nWe will discuss the choice of hypotheses quite a lot since it is one \nof the most crucial design decisions in machine learning. \n\n</details>\n\n:::\n\n\n\n## Exercise 4: Predicting `abalone`\n\n::: {.callout-note title=\"Learning goals\" icon=false}\nTBD\n:::\n\nWe want to predict the age of an abalone using its longest shell measurement and \nits weight.\nThe `abalone` data can be found here: [https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data](https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data).\n\nPrepare the data as follows:\n\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-data |  | echo:true,warning:false,asis:true,eval:false -->\n\n### Python\nCall `from sklearn.metrics import mean_absolute_error`.\n:::\n\n***\nPlot `LongestShell` and `WholeWeight` on the $x$- and $y$-axis, respectively, and color points according to `Rings`.\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-plot |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\nCall `from sklearn.metrics import mean_absolute_error`.\n:::\n</details> \n:::\n\n***\nUsing `mlr3`/`sklearn`, fit a linear regression model to the data.\n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-task |  | echo:true,warning:false,asis:true,eval:false -->\n.\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-predict |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\nCall `from sklearn.metrics import mean_absolute_error`.\n:::\n</details> \n:::\n\n***\nCompare the fitted and observed targets visually.\n\n<details> \n<summary>*Hint*</summary>\n::: {.panel-tabset}\n### R\nUse `$autoplot()` from `mlr3viz`.\n\n### Python\ntbd\n:::\n</details> \n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-viz |  | echo:true,warning:false,asis:true,eval:false -->\n\n### Python\ntbd\n:::\n</details> \n:::\n\n***\nAssess the model's training loss in terms of MAE.\n\n<details> \n<summary>*Hint*</summary>\n::: {.panel-tabset}\n### R\nCall `$score()`, which accepts \ndifferent `mlr_measures`, on the prediction object.\n\n### Python\nCall `from sklearn.metrics import mean_absolute_error`.\n:::\n</details> \n\n::: {.content-visible when-profile=\"solution\"}\n<details> \n<summary>**Solution**</summary>\n::: {.panel-tabset}\n### R\n<!-- 12A0366C|/home/lisa/Documents/0_work/repos_teaching/lecture_i2ml/exercises/supervised-regression-quarto/regression.qmd|:_r.ipynb#abalone-eval |  | echo:true,warning:false,asis:true,eval:false -->\n### Python\ntbd\n:::\n</details> \n:::",
    "supporting": [
      "regression_files/figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}