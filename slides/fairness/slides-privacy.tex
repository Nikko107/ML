\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
%\newcommand{\titlefigure}{figure/fig-title-knn-3d-contour.png}
\newcommand{\learninggoals}{
\item XXXX
}


\title{Introduction to Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\begin{document}
\lecturechapter{Privacy and Data Protection}
\lecture{Introduction to Machine Learning}


%-------------------------------------------------------------------------------
\begin{vbframe}{Motivation}
\vfill

\textbf{Medical Information}

In order to keep medical records private, names, ids and addresses are delted from public data sets, but \enquote{87\% of the U.S. population is uniquely identified by date of birth, gender, postal code}. (Sweeney, 2000)

\vfill

\textbf{Netflix Prize}

In 2006, Netflix offered \$1 million dollar for improving the movie recommandation algorithm. They published 100 million \enquote{anonymized} movie ratings. 16 days later, researchers were able to identify many users and their viweing history by matching the data sets with movie ratings on the Internet Movie Database. (Narayanan and Shmatikov, 2008)


\vfill
\begin{tiny}
\begin{singlespace}
Collect Examples for why we need privacy, GDPR, encryption etc.
Good: Medical context
Sweeney, Latanya. "Simple demographics often identify people uniquely." Health (San Francisco) 671.2000 (2000): 1-34.\\
Narayanan, Arvind, and Vitaly Shmatikov. "Robust de-anonymization of large sparse datasets." 2008 IEEE Symposium on Security and Privacy (sp 2008). IEEE, 2008.
\end{singlespace}
\end{tiny}
\end{vbframe}
%-------------------------------------------------------------------------------
\begin{vbframe}{Judicial Perspective -- GDPR}

\begin{itemize}

\item Privacy is enforced in different legal frameworks. In the EU, the General Data Protection Regulation (GDPR) was enforced in 2018. 
% \item We can distinguish between three different types of data: 
%   \begin{itemize}
%     \item public: publicly available and not considered personal or sensitive.
%     \item personal: \enquote{any information relating to an identified or identifiable natural person} such as the name or an id. (GDPR)
%     \item sensitive: personal data which must be treated with additional security like racial origin, political opinion, religious beliefs, and genetic data.
%   \end{itemize}

\item Data Science is affected in three areas: data processing, bias and dicrimination and the right to explanation.
%https://thomaswdinsmore.com/2017/07/17/how-gdpr-affects-data-science/
\item Basically, GDPR forbids to process any personal data except there is an acceptable reason. Personal data is \enquote{any information relating to an identified or identifiable natural person} such as the name or an id. This highly influences the modelling process.

\item GDPR gurantees the consumer that they are not \enquote{subject to a decision […]which is based solely on automated processing and which provides legal effects (on the subject).} In practice, this could mean that credit ratings by machine learning models must be explainable. 

\item Lastly, GDPR required the automated descion-making to avoid any form of discrimination and bias. Attributes like gender or ethnic origin should not impact the outcome. 

\end{itemize}

\framebreak 

Other important laws in this context are: 

XXX


\end{vbframe}
%-------------------------------------------------------------------------------
\begin{vbframe}{Encryption}

\begin{itemize}

\item To process personal information, data can be encrypted. 

\item Encryption is a process of converting the origial data representation into an alternative representation (cipher text). Decryption is the conversion of the encrypted data back to the original data set. 

\item We can encrypt and decrypt data by using a key. A key is normally a string of numbers or letters which can processed by the cryptographic algorithm.

\item To maintain the privacy idea, it is important to consider how the keys are generated and how they can be exchanged.  

\end{itemize}

\framebreak
\begin{itemize}
\item We differntiate between symmetric and asymmetric cryptography.
\item In symmetric cryptography, there is one key for encryption and decryption. 
\end{itemize}
\vspace{-0.2cm}
\begin{center}
\includegraphics[width=0.55\textwidth]{figure_man/privacy-sym-encryp.png}
%FIGURE SOURCE: https://docs.google.com/presentation/d/19kLVov1D2yIvliGca7mHiqpTB5OURWi-dsgs9GjBzho/edit?usp=sharing
\end{center}
\vspace{-0.5cm}
\begin{itemize}
\item In asymmetric cryptography, the keys for encryption (public key) and decrpytion (private key) are different. 
\end{itemize}
\vspace{-0.2cm}
\begin{center}
\includegraphics[width=0.55\textwidth]{figure_man/privacy-asym-encryp.png}
%FIGURE SOURCE: https://docs.google.com/presentation/d/19kLVov1D2yIvliGca7mHiqpTB5OURWi-dsgs9GjBzho/edit?usp=sharing
\end{center}

\end{vbframe}
%-------------------------------------------------------------------------------
\begin{vbframe}{De-identification and Re-identification}
\begin{itemize}
\item \textbf{De-identification} is a primary method of ensuring privacy. It is a technique that masks or deletes personal identifiers from personal information, or replaces them with surrogate personal identifiers.
\item To protect an individual's privacy, all personal identifiers must be de-identified.

\item \textbf{Re-identification} is the process of matching anonymous data to publicly accessible information, or auxiliary data, in order to determine the identity of the person to whom the data correspond.

\end{itemize}
%-------------------------------------------------------------------------------
\framebreak
%-------------------------------------------------------------------------------


\end{vbframe}
%-------------------------------------------------------------------------------
\begin{vbframe}{Differential Privacy}
\begin{itemize}
\item By adding noise to the computations, differential privacy (Dwork, Roth et al., 2014) promises that the data cannot be reverse-engineered.
\item Differential privacy requires that the outcome of an algorithms does not change \textit{much}, if we remove an individual from the data set. This includes also unusual data records.
\end{itemize}

\begin{center}
\includegraphics[width=0.6\textwidth]{figure_man/privacy-differential.pdf}
%FIGURE SOURCE: https://docs.google.com/drawings/d/1zN481kuU0nc_6WtRjV_4avAzykXoLoJ_obdA3F5e1F8/edit?usp=sharing
\end{center}
\vfill
\begin{tiny}
\begin{singlespace}
Dwork, Cynthia, Aaron Roth et al. 2014. “The algorithmic foundations of differential privacy.” Foundations and Trends in Theoretical Computer Science 9(3-4):211–407.
\end{singlespace}
\end{tiny}
%-------------------------------------------------------------------------------
\framebreak
%-------------------------------------------------------------------------------

Formally, differnential privacy is a ???.

Differential privacy does protect the information of single persons, but not of groups. 

\end{vbframe}
%-------------------------------------------------------------------------------
\endlecture
\end{document}
