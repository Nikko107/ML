\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}


\title{Introduction to Machine Learning}

\begin{document}

\titlemeta{% Chunk title (example: CART, Forests, Boosting, ...), can be empty
  Random Forest 
  }{% Lecture title  
  Proximities
}{% Relative path to title page image: Can be empty but must not start with slides/
  figure_man/Proximity_plot.png
}{% Learning goals, wrapped inside itemize environment
  \item Understand how a random forest can be used to define proximities of observations
  \item Know how proximities can be used for missing data, outliers, mislabeled data and a visualization of the forest
}

\begin{vbframe}{Proximities}
RFs have an in-built similarity measure between pairs of observations: 

\begin{center}
% FIGURE SOURCE: https://docs.google.com/presentation/d/1lDW9HEeNEGwJR1tmhAiOhySibzl6tXLxqePsKtpbb_M/edit#slide=id.g2e20bede50d_0_0
\includegraphics[width=1\textwidth]{figure_man/forest-proximities.png}
\end{center}

\begin{itemize}
  \item Once a random forest has been trained, all of the training data is put through each tree (both in- and out-of-bag).
  \item The proximity $\operatorname{prox}\left(\xi, \xi[j]\right)$
  between two observations $\xi$ and $\xi[j]$ is calculated by measuring the number of times that these two observations are placed in the \textbf{same terminal node of the same tree}, divided by the number of trees: $\operatorname{prox}\left(\xi[1], \xi[2]\right) = 1/3$
  \item The proximities of all observations form a symmetric $n \times n$ matrix.
\end{itemize}

\end{vbframe}


\begin{vbframe}{Visualizing the forest}

\begin{itemize}
  \item The values $1 - \operatorname{prox}\left(\xi, \xi[j]\right)$ can be thought of as distances in a high-dimensional space
  \item They can be projected onto a low-dimensional space using metric multidimensional scaling (MDS)
  \item Metric multidimensional scaling uses eigenvectors of a modified version of the proximity matrix to get scaling coordinates
\end{itemize}

\framebreak

\begin{center}
\includegraphics[width=0.7\textwidth]{figure_man/Proximity_plot.png}
\end{center}
\tiny image from G. Louppe (2014) \emph{Understanding Random Forests} \texttt{arXiv:1407.7502}. 

\framebreak

\begin{itemize}
  \item \normalsize The figure depicts the proximity matrix learnt for a 10-class handwritten digit classification task
  \begin{itemize}
  \item proximity matrix distances projected onto the plane using multidimensional scaling
  \item samples from the same class form identifiable clusters, which suggests that they share a common structure
  \item also shows the fact for which classes errors occur, e.g.,  digits 1 and 8 have high within-class variance and have overlaps with other classes 
  \end{itemize}
\end{itemize}

\end{vbframe}

\begin{vbframe}{Inputing missing data}
\begin{enumerate}
\item Replace missing values for a given variable using the median of the non-missing values
\item Get proximities
\item Replace missing values in observation $\xi$ by a weighted average of non-missing values, with weights proportional to the proximity between observation $\xi$ and the observations with the non-missing values
\end{enumerate}
Steps 2 and 3 are then iterated a few times. %(5 to 6 times)
\end{vbframe}

\begin{vbframe}{Locating outliers}
Locating outliers: 
\begin{itemize}
\item An outlier is an observation whose proximities to all other observations are small
\item Measure of outlyingness can be computed for each observation in the training sample
\item If the measure is unusually large, the observation should be carefully inspected
\end{itemize}
\end{vbframe}

\begin{vbframe}{Identifying mislabeled data}
Identifying mislabeled data:
\begin{itemize}
\item Instances in the training data set are sometimes labeled ambiguously or incorrectly, especially in \enquote{manually} created data sets.
\item Proximities can help in finding them: they often show up as outliers in terms of their proximity values. 
\end{itemize}
\end{vbframe}

\begin{vbframe}{Discussing proximities}
\begin{itemize}
  \item Proximities are one of the most useful tools in RFs
  \item They measure similarity ("closeness" or "nearness") of observations
  \item With large datasets, it is not possible to fit a $n \times n$ matrix into fast memory
  \item A modification is needed - reduce the required memory size to $n \times M$, where $M$ is the number of trees in the forest
\end{itemize}
\end{vbframe}

\endlecture
\end{document}
