\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-ensembles.tex}

\newcommand{\titlefigure}{figure_man/forest.png}
\newcommand{\learninggoals}{
\item Understand random forests as extension of bagging
\item Understand the algorithm of random forests
\item Understand the performance evaluation of random forests
\item Understand the (dis-)advantages of random forests}

\title{Introduction to Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
\institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-lmu.github.io/lecture\_i2ml}}
\date{}

\begin{document}


\lecturechapter{Random Forests: Overview}
\lecture{Introduction to Machine Learning}
\sloppy


\begin{vbframe}{Bagging}
\begin{itemize}
  \item Combination of bootstrapping data and aggregrating models (Bagging = \textbf{B}ootstrap \textbf{Agg}regation)
  \item Approach to stabelize learners and thereby reduce variance of predictions
\begin{enumerate}
  \item Draw m subsamples from dataset via bootstrapping
  \item Construct m base learners from these m subsamples (can be done in parallel)
  \item Aggregate the m single base learners to construct one ensemble learner
  \item Ensemble learner is used to make predictions
\end{enumerate}
\end{itemize}
\end{vbframe}


\begin{vbframe}{Random Forests and Bagging}
Several ways to further improve bagging ensembles e.g.: 
\begin{itemize}
  \item Increase variance of the ensemble to improve performance
  \item Decorrelate single base learners to improve performance
\end{itemize} 
\ \newline
Random forests implement these improvement measures and thereby extend bagging:
\begin{itemize}
  \item RF implement the bagging algorithm using CARTs as base learners
  \item Decorrelation by randomizing splits in each base learner
  \item Increased variance of the ensemble by fully expanding each learner (no pruning etc.)
\end{itemize}
\end{vbframe}


\begin{vbframe}{Random forest algorithm }
\begin{enumerate}
  \item For each of the m base learners do:
  \begin{itemize}
    \item Draw subset of data via bootstrapping and train CART 
    \item Per node/split randomly choose mtry features and only consider these mtry features in respective split
  \end{itemize}
  \item Aggregate the predictions of m the base learners to get the ensemble prediction
  \begin{itemize}
    \item Regression: Aggregation via taking the mean
    \item Classification: Aggregation via majority vote
  \end{itemize}
\end{enumerate}
\end{vbframe}

\begin{vbframe}{Random Forest Performance Evaluation}
\begin{itemize}
  \item No need to define an explicit train and test set due to bootstrapping 
  \item OOB errors are used to estimate the performance of the random forest: 
  \begin{enumerate}
    \item Calculate the OOB prediction per observation for each tree in ensemble 
    \item Aggregate the OOB prediction per observation to get ensemble OOB prediction for observation
    \item Use ensemble OOB predictions to calculate the estimated OOB error for the ensemble (= unbiased estimate for GE) 
  \end{enumerate}
\end{itemize}
\end{vbframe}

%\begin{vbframe}{Feature importance}
%Knowing the importance of each feature in a given learner/model helps with interpetability 
%and feature selection.\\
%Different approaches to determine feature importance:
%\begin{itemize}
%  \item Improvement split criterion:
%  \item Via Permutating features: 
%\end{itemize}
%\end{vbframe}

\begin{vbframe}{Advantages and Disadvantges}
\textbf{Advantages}
\begin{itemize}
  \item All advatages of trees
  \item Reduces variance/stablizes predictions w.r.t. a single CART
  \item Built in performance evaluation with an unbiased estimate for GE
  \item Built in analysis of feature importance and observation proximities
\end{itemize}
\ \newline
\textbf{Disadvantages}
\begin{itemize}
  \item Computationally expensive (especially for large ensembles) 
  \item No eas way to visually interpret a random forest (in contrast to a single CART) 
\end{itemize}
\end{vbframe}

\endlecture
\end{document}
