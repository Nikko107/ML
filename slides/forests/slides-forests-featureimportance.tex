\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}
\input{../../latex-math/ml-trees.tex}
\input{../../latex-math/ml-ensembles.tex}

\title{Introduction to Machine Learning}

\begin{document}

\titlemeta{% Chunk title (example: CART, Forests, Boosting, ...), can be empty
  Random Forest 
  }{% Lecture title  
  Feature Importance
}{% Relative path to title page image: Can be empty but must not start with slides/
  figure/forest-fimp_gini.png
}{% Learning goals, wrapped inside itemize environment
  \item Understand that the goal of defining feature importance is to enhance interpretability of the random forest
  \item Be able to define feature importance based on improvement in split criterion
  \item Be able to define feature importance based on permutations of OOB observations
}

\begin{vbframe}{Feature Importance}

RFs improve accuracy by aggregating multiple decision trees but \textbf{lose interpretability} compared to a single tree. Evaluating individual feature contributions in RFs is challenging.

% TODO visualiziation

\textbf{Feature Importance:}
\begin{itemize}
\item Feature importance helps rectify lost interpretability!
\item \textbf{Basic idea}: by how much would the performance of the RF \textit{decrease} if a specific feature were removed or rendered useless?
\end{itemize}

\end{vbframe}

\begin{vbframe}{Impurity importance}
\vspace{-2ex}
\begin{algorithm}[H]
\small
\caption*{Measure based on improvement in split criterion}
\begin{algorithmic}[1]
  \For{features $x_j$, $j = 1$ to $p$}
  \For{tree base learners $\blh$, $m = 1$ to $M$}
  \State {Find all nodes $\Np$ in $\blh$ that use $x_j$.} 
  \State {Compute improvement in splitting criterion achieved by them.}
  \State {Add up these improvements.}
  \EndFor
  \State {Add up improvements over all trees to get feature importance of $x_j$.}
  \EndFor
\end{algorithmic}
\end{algorithm}
\small
E.g. using the Gini index to measure the total decrease in node impurity:

\vspace{-1ex}

\begin{center}
%TODO Schriftgröße
\includegraphics[width=0.7\textwidth]{figure/forest-fimp_gini.png}
\end{center}

\end{vbframe}

\begin{vbframe}{Permutation importance}
%TODO visualization

\begin{minipage}[b]{0.35\textwidth}
% FIGURE SOURCE: https://docs.google.com/drawings/d/1A0hdwZrwHI8zwMdchY-rn0bpGcNYO-Y4te20DMSwQ84/edit

\includegraphics[width = 0.9\textwidth]{figure_man/forests-featimp-new}
\end{minipage}%
\begin{minipage}[b]{0.65\textwidth}
% TODO verallgemeinern
% BITTE PRüFEN
\begin{algorithm}[H]
\scriptsize
\caption*{\small{Measure based on permutations of OOB obs.}}
\begin{algorithmic}[1]
  \State Calculate $\widehat{\mathrm{GE}}_{\text{OOB}}$
  \For{features $x_j$, $j = 1$ to $p$}
    \State {Perform permutation $\psi_j$ on $x_j$ to distort feature-target relation for $x_j$.}
    \For{distorted observations $(\mathbf{x}^{(i)}_{\psi_j}, \yi)$, $i = 1$ to $n$}
    \State {Compute OOB prediction $\yih_{\text{OOB}, \psi_j}$.}
    \State {Compute corresponding loss $L(\yi, \yih_{\text{OOB}, \psi_j})$.}
  \EndFor
  \State {Estimate importance of $j$-th feature}
  \State {$\widehat{\text{FI}_j} = \widehat{\text{err}}_{\text{OOB}, \psi_j} - \widehat{\mathrm{GE}}_{\text{OOB}}  $}
  \State {\phantom{$\widehat{\text{VI}_j}$} $= \meanin L(\yi, \yih_{\text{OOB}, \psi_j}) - \widehat{\text{err}}_{\text{OOB}}$.}
  \EndFor
\end{algorithmic}
\end{algorithm}
\end{minipage}

\vspace{-1em}
\begin{center}
%TODO Schriftgröße
\includegraphics[width=0.50\textwidth]{figure/forest-fimp_perm.png}
\end{center}

\end{vbframe}

% \begin{vbframe}{Variable Importance}

% \begin{itemize}
%   \item Measure based on permutations of OOB observations: MeanDecreaseAccuracy (average decrease in accuracy for predictions of OOB observations after permuting the $j$-th feature)
% \end{itemize}

% \end{vbframe}

% TODO hier noch summary!


\endlecture
\end{document}
