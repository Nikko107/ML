\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\newcommand{\titlefigure}{figure_man/pexels-karolina-grabowska-4472108.jpg}
% stock free image from pexels.com


\newcommand{\learninggoals}{
\item Understand the main idea behind tuning,
\item why tuning matters,
\item and why tuning is difficult
}

\title{Introduction to Machine Learning}
% \author{Bernd Bischl, Christoph Molnar, Daniel Schalk, Fabian Scheipl}
% \institute{\href{https://compstat-lmu.github.io/lecture_i2ml/}{compstat-% lmu.github.io/lecture\_i2ml}}
\date{}
\begin{document}

\lecturechapter{Tuning: In a Nutshell}
\lecture{Introduction to Machine Learning}
\sloppy


\begin{vbframe}{What is Tuning?}
\begin{itemize}
\item \small Tuning is the process of selecting the best hyperparameters, denoted as $\lambda$, for a machine learning model
\item \small Hyperparameters are the parameters of the learner (versus model parameters $\theta$)
\item \small Consider a guitar analogy: Hyperparameters are akin to the tuning pegs. Learning the best parameters \bm{$\thetabh$} - playing the guitar - is a separate process that depends on tuning!
\end{itemize}

\begin{center}
\includegraphics[width = 0.75\textwidth]{figure_man/riskmin_bilevel3.png}
\end{center}

\end{vbframe}


\begin{vbframe}{Why Tuning Matters}
\begin{itemize}
\item \small Just like a guitar won't perform well when out-of-tune, properly tuning a learner can drastically improve the resulting model performance
\item \small Tuning helps find a balance between underfitting and overfitting
\end{itemize}

\begin{center}
\vspace{3em}
\includegraphics[width = 0.9\textwidth]{figure/tuning_importance.png}
\end{center}

\end{vbframe}


\begin{vbframe}{How hard could it be?}
\begin{itemize}
\item \small Very difficult: There are lots of different configurations to choose from, known as the hyperparameter space, denoted by $\Lam$ (analogous to $\Theta$)
\item \small Black box: If one opts for a configuration $\lamv \in \Lam$, how can its performance be measured (and compared)?
\item \small Well-thought-out approaches - black box optimization techniques - are needed!

\begin{center}
\vspace{2em}
\includegraphics[width=200pt]{figure/cart_tuning_balgos_1.pdf}
\end{center}

\end{itemize}
\end{vbframe}


\begin{vbframe}{Naïve Approaches}
Let's start with two naïve approaches -

\textbf{Grid Search} and \textbf{Random Search}:

\vspace{2em}
\begin{minipage}{0.51\textwidth}
\begin{center}
\textbf{Grid Search}
\end{center}

\includegraphics[width=190pt]{figure/cart_tuning_balgos_1.pdf}
\end{minipage}
\begin{minipage}{0.48\textwidth}
\begin{center}
\textbf{Random Search}
\end{center}

\includegraphics[width=190pt]{figure/cart_tuning_balgos_2.pdf}
\end{minipage}

\vspace{2em}
\small Beyond these basic methods, there are more sophisticated techniques which operate on certain assumptions about the objective function. These assumptions enable them to search for optimal solutions more efficiently.

\end{vbframe}


\begin{vbframe}{Pipelines in Machine Learning}
% Introduce the concept of pipelines in a more engaging way
Pipelines are like the assembly lines in machine learning. They automate the sequence of data processing and model building tasks, ensuring efficiency and consistency.

\textbf{Why Pipelines Matter:}
\begin{itemize}
\item \small \textbf{Streamlined Workflow:} Automates the flow from data preprocessing to model training.
\item \small \textbf{Reproducibility:} Ensures that results can be reproduced consistently.
\item \small \textbf{Error Reduction:} Minimizes the chance of human errors in the model building process.
\end{itemize}

\textbf{Simple Pipeline Example:}
\begin{itemize}
\item A basic pipeline might include data normalization, feature selection, and a learning algorithm.
\end{itemize}
\end{vbframe}

\begin{vbframe}{Pipelines and AutoML}
AutoML leverages pipelines to automate the process of applying machine learning to real-world problems. It simplifies tasks like model selection, hyperparameter tuning, and cross-validation.

\vspace{1em}

\textbf{Key Components of AutoML Pipelines:}
\begin{itemize}
\item \small \textbf{Data Preprocessing:} Automatic handling of missing values, encoding categorical variables, etc.
\item \small \textbf{Feature Engineering:} Automated feature selection and transformation.
\item \small \textbf{Model Selection:} Evaluating and choosing the best model automatically.
\item \small \textbf{Hyperparameter Optimization:} Finding the best model settings without manual intervention.
\end{itemize}
\end{vbframe}

\endlecture
\end{document}